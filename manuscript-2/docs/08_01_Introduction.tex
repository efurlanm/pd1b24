%========================================
\chapter{INTRODUCTION}
\label{ch:intr}
%========================================

This thesis aims to explore Physics-Informed Machine Learning (PIML) alternatives to replace part of the ecRad radiation numerical module, which is used by the global weather and climate model Integrated Forecasting System (IFS) of the European Centre for Medium-Range Weather Forecasts (ECMWF). The IFS model was developed and maintained jointly by the ECMWF, based in Reading, England, and Météo-France, based in Toulouse, France. PIML is described in \autoref{sec:piml}, while the initial class of Physics-Informed Neural Networks (PINN) methods is described in \autoref{sec:pinn}. The ecRad radiation module appears in \autoref{sec:ers}. Former work in this thesis research included a PINN implementation for a test case, shown in this document. The objectives of this thesis are then shown in \autoref{sec:otr}.

%========================================
\section{Physics-Informed Machine Learning (PIML) }
\label{sec:piml}
%========================================

PIML is a set of methods and tools that systematically integrate Machine Learning (ML) algorithms with physical constraints and mathematical models developed in scientific and engineering domains. As opposed to purely data-driven methods, PIML models can be trained from additional information obtained by enforcing physical laws such as energy and mass conservation. More broadly, PIML models can include abstract properties and conditions such as stability, convexity, or invariance. The basic premise of PIML is that the integration of ML and physics can yield more effective, physically consistent, and data-efficient models. Recent advances in PIML for dynamical system modeling and control includes: (i) physics-informed learning for system identification; (ii) physics-informed learning for control; (iii) analysis and verification of PIML models; and (iv) physics-based digital twin, which consists of parameterized components whose physical properties can be altered to provide data from source systems that are identical to the target system
\cite{Nghiem2023}.

According to \citeonline{Karniadakis2021}, despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. In this context, ML emerges as a promising alternative, being a current research thread. However, training deep neural networks may require big data, which is not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws, for example, at random points in the continuous space-time domain. Such physics-informed learning integrates noiseless or noisy data and mathematical models implemented by neural networks or other ML methods. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Considering PIML approaches, some of the prevailing trends, capabilities and limitations in embedding physics into ML are discussed. Some PIML applications both for forward and inverse problems are presented, including discovering hidden physics and tackling high-dimensional problems.

PIML is a methodology that improves model accuracy and interpretability by combining physics concepts and ML techniques, enables more robust predictions while reducing the need for large amounts of training data, and has numerous potential applications in science and engineering, such as modeling physical systems, solving partial differential equations, and performing inverse analysis and optimization. Some approaches used in PIML can be classified as: physics-constrained ML, physics-guided ML, physics-encoded ML, data augmentation through physics principles, transfer learning from physics-based synthetic data to experimental data, and delta-learning physics correction to improve physics generalization and delta-learning unknown physics to represent unmodeled physical phenomena \cite{Tronci2024}. In addition, there is also a need for new PIML standardized frameworks and patterns, as well as new PIML approaches, to enable scalable and robust implementations. 

A first PIML approach was given by the Physics-Informed Neural Networks (PINN), which employ DNN for problems related to the solving of Partial Differential Equation (PDE), as described below.


%========================================
\section{Physics-Informed Neural Networks}
\label{sec:pinn}
%========================================

Previous work related of this thesis research evaluated the parameter discovery of the data-driven one-dimensional Burgers' Equation (1D Burgers) using a PINN implementation. 

Concerning PINNs, many simulations are mathematically modeled by PDEs, which have derivatives in space and time. Typically, the coefficients of these derivatives are unknowns that express physical properties of the problem being modeled by the PDE, which is usually solved by standard Numerical Models (NM) like the finite difference method. Recent work has proposed to solve a PDE, or discover the parameters of the PDE based on data, using Deep Neural Network (DNN). The universal approximation theorem states that a DNN can approximate any continuous function, as long as the network has a sufficient number of hidden layers and employs nonlinear activation functions \cite{Hornik1989}. In any case, for parameter resolution or discovery, depending on the architecture employed, the DNN training input is provided by sample points, which compose a subset of the full set of known points of the function in the space and time domain. These sample points can be conveniently selected in order to increase its number of data related to initial (IC) and boundary conditions (BC). These sample points are then called Collocation Points (CP) \cite{Basdevant1986}, a name that came from standard NMs. 

However, either for solving a PDE or for  parameter discovery of the PDE, the training phase of DNN requires a high number of sample points in order to obtain accurate solutions. Sample points can be obtained either by observation or using synthetic data from a known model. PINNs, which are DNN embedding underlying physical equations as prior knowledge, were proposed in order to make feasible the use of a lower number of sample points in the training phase \cite{Cuomo2022}. 

PINNs can be used for solving the direct problem, also called inference or solution, where the PDE and parameters are known, but not the result of the simulation. In the inverse problem, also called system identification or discovery, the CPs are used to discover the PDE parameters that best fit the exact dataset, thus finding the governing equations that rule the considered dynamic system modeled by the PDE. Dynamic systems are a diverse and well-studied class of mathematical objects used to model systems that change over time. Once identified, these equations can be utilized to predict future states, inform control inputs, or facilitate theoretical research using analytical approaches. Also considering the inverse problem, in the case of noisy datasets, PINNs can also perform data-driven parameter discovery, thus obtaining a more accurate model that allows to reproduce the set of sample points with less or no noise \cite{Zhou2024}.

PINNs are employed for unsupervised learning when trained only on physical equations, and for supervised learning when dealing with noisy data or solving an inverse problem, and generally the related physical equations are used in the loss function \cite{Cuomo2022}. Furthermore, PINN can be used in cases where the model (or the PDE that describes it) is known, to reduce the size of the dataset required to train the DNN, thereby increasing efficiency, or when there is noise in the sample, and we want the underlying physical law to help deal with it.

% alterado a localização no texto (Prof. Roberto)
Models using PINN are effective and efficient for ill-posed and inverse problems, and when combined with domain decomposition, can scale to larger problems \cite{Sharma2023a}. Neural network-based regression algorithms can be implemented effectively and simply, even without the use of mesh discretization. Future PINN research topics include operator regression, the search for new variables, intrinsic representations, and equivariant neural network topologies with integrated physical restrictions. 

\citeonline{Raissi2019} published an article on PINNs with 8956 citations (as of May 2024). The paper describes PINNs as DNNs trained to tackle supervised learning tasks when dealing with noisy data or inverse issues, and unsupervised learning when trained simply on physical equations, but conforming with physical rules, which are commonly described by nonlinear PDEs \cite{Cuomo2022}.

It also describes the use of DNNs to solve PDEs and obtain physics-informed surrogates of the physical model that are fully differentiable in all coordinates and free parameters. PINNs form a new class of data-efficient universal function approximators, which can be effectively trained using small datasets, and which may encode any underlying physical law. 

DNN training data can be randomly sampled from observational data, or through simulations using synthetic data generated by a NM. Except for the latter, as long as a sufficient number of CP is available, a standard DNN can solve the PDE, but otherwise a PINN would be required. A PINN uses a specific loss function incorporating the related PDE and its parameters, in such a way that during the training phase using the set of CP, the applicable physical law is incorporated \cite{Cuomo2022}.

The most common PINN architectures are Multi-Layer Perceptrons (MLPs), Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). Newer architectures are Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN) and Bayesian Deep Learning (BDL) \cite{Vladimirova2018}.

\citeonline{Cuomo2022} published an article with 737 citations (as of April 2024) that provides a complete analysis of PINNs, and discusses the benefits and drawbacks of various PINN variations, including variational hp-VPINN, conservative PINN (CPINN), and physically constrained DNNs (PCNN). Additionally, PINNs can function as Reinforcement Learning (RL) agents. According to the same study, most of the research focused on PINN customization through the use of different activation functions, DNN architectures, gradient optimization techniques, and loss functions. Many PINN applications have been proposed and, according to the case, a PINN implementation can be used with advantage as a substitute to a standard numerical method, as in the case of the  Finite Element Method (FEM).

Considering that PINNs were recently proposed, there is still room for improvements and also for new theoretical considerations. 
\citeonline{Kim2021} proposed a general taxonomy of PINN conceptual levels, based on a literature review about dynamic systems: (i) what type of DNN is used, (ii) how physical knowledge is represented, and (iii) how physical information is integrated. The PINN is not the only DNN approach used to solve PDEs, although it seems to be the leading one in terms of number of articles. The PINN mainstream is still the PDE direct problem, but the number of works proposing PINNs to solve PDE inverse problems has been increasing. For instance, the use of CP is emphasized in some articles \cite{Meng2020,Yang2019,Raissi2019}. Other works present the Conservative PINN (CPINN) \cite{Jagtap2020}, and the Physically Restricted Neural Networks (PCNNs) \cite{Zhu2019,Sun2020,Liu2021}.

PINNs may model the PDE with unknown initial and boundary conditions (called soft BC), as detailed in Raissi et al. \cite{Raissi2019}, a work that proposed the name Physics-Informed Neural Network (PINN). There are also PCNNs, a class of \textit{data-free} PINNs, which impose known initial and boundary conditions via a customized DNN architecture (hard BC) that also include the PDE in the loss function. Soft restrictions in DNNs are commonly stated as penalty terms in the loss function. These penalties urge the network to adhere to the intended behavior while allowing for some flexibility. Hard constraints, in turn, are often defined as specific conditions that network output parameters must meet, which are indirectly enforced using techniques such as the penalty approach and the improved Lagrangian method, which penalize violations of the constraints, effectively transforming hard constraints into soft ones during optimization. \cite{Lu2021b,Nandwani2019,Yao2023}.

Recently, numerous frameworks have been presented, including the Deep Ritz Method (DRM) \cite{E2017}, in which the loss function value is defined as the energy required to solve the problem. There are alternative implementations based on the Galerkin method, also known as the Petrov-Galerkin method, in which the loss function value is calculated by multiplying the residue by a test function. This approach results in the Deep Galerkin Method (DGM) when the residue is volumetric \cite{Sirignano2018}. Given that a Galerkin technique is utilized with CP, it can be considered a version of PINN, namely a hp-VPINN (Kharazmi et al.) \cite{Kharazmi2021}.

Challenges and future prospects for PINN include its use and implementation for a variety of application involving real-world equations. Applications include everything from convergence and stability to boundary condition management, DNN design, general PINN architecture design, and more. PINN have the potential to be a useful tool for solving high-dimensional PDEs that are important in physics, engineering, finance, and other areas. However, PINNs generally cannot accurately approximate PDE solutions in comparison to other specific NMs that are optimized for a single PDE \cite{Cuomo2022}. It is worth to note that some PINN implementations that appear in the literature lack reproducibility and documentation, restricting new potential users to employ them.

The extension of PINN applications for 2D or 3D problems poses additional challenges since training complexity grows, requiring more complex architectures and larger batch sizes. As a consequence, training may be constrained by GPU memory, and longer training times are required for convergence to the solution \cite{Nandi2021}. There is a trend to include PINN into standard libraries written in Fortran and C/C++, as well as integrating PINN solvers into older high performance computing (HPC) applications \cite{Markidis2021}. For instance, PINN may be implemented on modern HPC clusters using the Horovod distributed training framework \cite{Sergeev2018}.


%========================================
\section{ecRad Radiation Scheme}
\label{sec:ers}
%========================================

This thesis proposed a PIML-base implementation of part of the ecRad radiation module, specifically the numerical gas-optics scheme, which is processing-demanding.  

Atmospheric radiation is the most influential scheme in numerical climate and weather models, requiring the solving of multiple instances of the radiative transfer equation to simulate absorption and scattering processes of the incident solar radiation, and also of the back-scattered terrestrial radiation. Cloud coverage and surface optical properties are considered, as well as the multiple greenhouse gases. Standard implementations of the IFS model do not solve the radiation module for every timestep and grid point (in latitude and longitude). The ecRad radiation module was developed by ECMWF, being operational with the IFS since 2017 \cite{Hogan2018}. It is extremely adjustable, with options for gas optics, cloud optics, aerosol optics, and radiative transfer solvers that represent cloud heterogeneity for different cases of cloud coverage.

% reler novamente o parágrafo:

Several authors proposed to replace the original numerical radiation module gas-optical scheme (RRTMGP) by DNN models in order to obtain beter computational performance \cite{Ukkonen2023,Veerman2021,Meyer2022a}. The kernel of the RRTMGP scheme is written in Fortran 90, and performs a 3D linear interpolation of the optical depth of the atmosphere for the considered 2D grid point using a lookup table indexing temperatures, pressures and mixing fractions. Among other libraries, these DNN implementations of the gas-optical scheme as  the TensorFlow library of the Python environment to perform training and validation of neural networks using a known dataset. The resulting models were then reproduced in Fortran 90 codes that embed the weights, biases, activation functions, etc. Thus, these codes can be coupled to the rest of the radiation module reproducing the operations that the DNN models would apply in the input data of the gas-optical scheme.

One of these works using DNN \cite{Chevallier2000} presented a speedup of $7$ using a DNN over a standard NM to estimate parameters for the Longwave Radiative Transfer model used by the IFS model of the European ECMWF. This shows the potential of using DNNs to obtain the parametric representations for the modeling of various atmospheric processes. \citeonline{Krasnopolsky2006} also cites speedups between $10$ and $10^5$ using a DNN over a standard NM in the parametrization of physical modules in oceanic and atmospheric models. \citeonline{Ukkonen2023} demonstrate speedups of about 3 when using DNN in the optical gas scheme, compared to the conventional RRTMGP scheme, promoting the acceleration of the overall ecRad module by a factor of 1.5. 

%---------------------------------------
% não faz parte dos objetivos (Prof. Roberto)
% precisa encontrar um lugar para inserir este texto
%---------------------------------------
%




% The most influential scheme in numerical climate and weather models is atmospheric radiation, and adequate treatment of radiative transfer is computationally challenging due to the complex absorption spectrum and also the fact that radiation parameterizations must optimize both efficiency and accuracy, in addition to including multiple greenhouse gases for future climate prediction. Solar and terrestrial radiation interact with the Earth's atmosphere, surface, and clouds, providing energy for climate and weather, and simulating these radiative pathways in numerical climate and meteorological models is challenging and typically requires large computational power. 
%
% As a result, it is necessary to efficiently model radiative effects, and the use of PIML could be an alternative to replace parts of standanrd numerical codes that are computationally intensive, such as, for example, the radiation part that calculates the optical properties of the atmosphere. The research carried out for this work shows that the use of DNN in the radiation module brought performance gains, paving the way for future work on PINN investigation and implementation. For the implementation of the DNN in the radiation module’s gas-optical scheme, the original numerical code (RRTMGP) was replaced by a DNN implementation written in Fortran, which takes as input a trained model dataset, and as output the DNN emulated predictions. In simple terms, the DNN model attempts to replace the primary computational kernel of the RRTMGP which is a 3-D linear interpolation of optical depth based on values stored in a lookup table for various temperatures, pressures, and mixing fractions. 
%
% To generate the trained model dataset, a Python code was used that uses the TensorFlow library and an MLP network. The training dataset for the DNN was obtained from various sources and, although real, the dataset was reduced in size so that it could be run offline on a standard PC. Once trained, the model is saved to disk for later use in the DNN implemented in Fortran in the main code. 


%========================================
\section{Objectives of the Thesis Research}
\label{sec:otr}
%========================================

There is a trend in weather and climate numerical models to replace standard microphysics modules by AI-based modules that are faster or even more accurate, as in the case of this work for the radiation module. Numerical models simulate the dynamics and the microphysics of the atmosphere and are written in Fortran 77 or 90. The model dynamics simulates the atmosphere as a fluid subjected to governing equations of fluid dynamics and thermodynamics, which are discretized for a 3D grid, usually composed of a 2D latitude-longitude grid for several vertical levels of pressure. The model physics simulate different processes like turbulence or radiation, being approximated or parameterized independently for each 2D grid point, and thus called subgrid processes.

This thesis work aims to develop a PIML-based implementation to replace the gas-optical scheme of the ecRad radiation module. The current numerical ecRad module implements a processing-demanding numerical model and therefore cannot be executed on every time steps and every grid points of the IFS ECMWF model. There are some works of different authors (\cite{Curcic2019,Krasnopolsky2008,Krasnopolsky2013,Ukkonen2020,Ukkonen2023,Veerman2021}) showing the feasibility of DNN-based implementations to replace the original gas-optical scheme in order to optimize its computational performance.

This thesis proposes an incremental approach for the AI-based radiation module implementations, starting with a non-PIML Deep Neural Network (DNN), followed by a PINN implementation, and then other PIMLs implementations. The simple no-PIML DNN approach was already implemented for an example test case, as shown here, as a starting point. Further tests involving DNN-only implementations will come after, and PINN-based and other PIML-based are certainly foreseen.

The proposed PIML-based implementation of the ecRad radiation module can be partially employed in the microphysics of the MPAS (Model for Prediction Across Scales) atmospheric model that was chosen for MONAN (Model for Ocean-laNd-Atmosphere predictioN) currently being developed by CPTEC/INPE and other Brazilian institutions. 
